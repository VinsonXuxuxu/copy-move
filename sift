import cv2
import numpy as np
import scipy.cluster.hierarchy as sch
import math
#from find_obj import filter_matches,explore_match
from matplotlib import pyplot as plt
from sklearn.cluster import AgglomerativeClustering
from sklearn import cluster
def dist(a, b):
    return math.sqrt(math.pow(a[0]-b[0], 2)+math.pow(a[1]-b[1], 2))
def dist_min(Ci, Cj):
    return min(dist(i, j) for i in Ci for j in Cj)
#dist_max
def dist_max(Ci, Cj):
    return max(dist(i, j) for i in Ci for j in Cj)
#dist_avg
def dist_avg(Ci, Cj):
    return sum(dist(i, j) for i in Ci for j in Cj)/(len(Ci)*len(Cj))

#找到距离最小的下标
def find_Min(M):
    min = 1000
    x = 0; y = 0
    for i in range(len(M)):
        for j in range(len(M[i])):
            if i != j and M[i][j] < min:
                min = M[i][j];x = i; y = j
    return (x, y, min)

#算法模型：
def AGNES(dataset, dist, k):
    #初始化C和M
    C = [];M = []
    for i in dataset:
        Ci = []
        Ci.append(i)
        C.append(Ci)
    for i in C:
        Mi = []
        for j in C:
            Mi.append(dist(i, j))
        M.append(Mi)
    q = len(dataset)
    #合并更新
    while q > k:
        x, y, min = find_Min(M)
        C[x].extend(C[y])
        C.remove(C[y])
        M = []
        for i in C:
            Mi = []
            for j in C:
                Mi.append(dist(i, j))
            M.append(Mi)
        q -= 1
    return C
#画图
def draw(C):
    colValue = ['r', 'y', 'g', 'b', 'c', 'k', 'm']
    for i in range(len(C)):
        coo_X = []    #x坐标列表
        coo_Y = []    #y坐标列表
        for j in range(len(C[i])):
            coo_X.append(C[i][j][0])
            coo_Y.append(C[i][j][1])
        pl.scatter(coo_X, coo_Y, marker='x', color=colValue[i%len(colValue)], label=i)

    pl.legend(loc='upper right')
    pl.show()

#C = AGNES(dataset, dist_avg, 3)
#draw(C)

def getSift(img):
    '''''
    得到并查看sift特征
    '''
    #img_path1 = '../../data/home.jpg'
    #读取图像
    #img = cv2.imread(img_path1)
    #转换为灰度图
    gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    #创建sift的类
    sift = cv2.xfeatures2d.SIFT_create()
    #在图像中找到关键点 也可以一步计算#kp, des = sift.detectAndCompute
    kp = sift.detect(gray,None)
    #print (type(kp),type(kp[0]))
    #Keypoint数据类型分析 http://www.cnblogs.com/cj695/p/4041399.html
    #print (kp[0].pt)
    print(len(kp))
    #计算每个点的sift
    des = sift.compute(gray,kp)
    print(len(des[0]))
    len_all=[]
    start=[]
    end=[]
    # kmean=cluster.KMeans(n_clusters=int(len(des[1])/5))
    # result=kmean.fit(des[1])
    # print(kmean.labels_)
    # result=kmean.predict(des[1])
    # print(result[1])
    # print(type(des[1]))
    for i in des[1]:
        for j in des[1]:
            tmp=np.sum(np.abs(i-j))
            #print(type(tmp))
            len_all.append(tmp)
        a=np.argsort(len_all)
        #print(len_all[0])
        if len_all[a[1]]/len_all[a[2]] <0.6:
            start.append(des[0][a[0]].pt)
            end.append(des[0][a[1]].pt)
        len_all=[]

    start.extend(end)
    print(type(start))
    n_clusters_ = 3
    ac = AgglomerativeClustering(linkage='average',n_clusters=n_clusters_)
    ac.fit(start)
    plt.figure(1)
    plt.clf()
    #print(type(start.extend(end)))
    #draw(AGNES(start,dist_avg,5))
    #disMat = sch.distance.pdist(start.extend(end), 'euclidean')
    #Z = sch.linkage(disMat, method='centroid')
    #plt.savefig('cluster.png')
    # clist = cluster.DBSCAN(min_samples=length/3)
    # start11 = kmean.fit_predict(start)
    # print(len(start))
    # print(start11)
    # print(start)
    # print(end)
    #H, status = cv2.findHomography(np.array(start), np.array(end), cv2.RANSAC, 10)
    #print(H)
    for (l,h) in zip(start,end):
        tup1=(int(l[0]),int(l[1]))
        tup2 = (int(h[0]), int(h[1]))
        cv2.line(img,tup1,tup2,(0,255,0),2)
    #pts1 = np.float32([start[0], start[1], start[2]])
    #pts2 = np.float32([end[0],end[1],end[2]])
    print(start[0])
    pts1 = np.float32([start[0], start[1], start[2]])
    pts2 = np.float32([end[0],end[1],end[2]])
    M = cv2.getAffineTransform(pts1, pts2)
    print(M)
#     #print (type(kp),type(des))
#     #des[0]为关键点的list，des[1]为特征向量的矩阵
#     # print("************************")
#     # print(type(des[1][0]))
#     # print(np.linalg.norm(des[1][0]-des[1][1]))
#     # print(type(des[0]), type(des[1]))
#     # #print(des[0],des[1][1])
#     # print(des[1][1])
#     # print("hhhhh")
#     # print(des[0][0].pt)
#     # #可以看出共有885个sift特征，每个特征为128维
#     # print(des[1].shape)
#     # #在灰度图中画出这些点
#     # cv2.drawKeypoints(gray,kp,img)
#     #cv2.imwrite('sift_keypoints.jpg',img)
    plt.imshow(img),plt.show()
    cv2.imwrite('result.jpg',img)
img=cv2.imread('001_F.png')
#print(img.shape)
getSift(img)
#
#
# # def matchSift3():
# #     '''''
# #     匹配sift特征
# #     '''
# #     img1 = cv2.imread('horse_orig.png', 0)  # queryImage
# #     img2 = cv2.imread('horse_fake.png', 0)  # trainImage
# #     sift = cv2.xfeatures2d.SIFT_create()
# #     kp1, des1 = sift.detectAndCompute(img1, None)
# #     kp2, des2 = sift.detectAndCompute(img2, None)
# #     # 蛮力匹配算法,有两个参数，距离度量(L2(default),L1)，是否交叉匹配(默认false)
# #     bf = cv2.BFMatcher()
# #     # 返回k个最佳匹配
# #     matches = bf.knnMatch(des1, des2, k=2)
# #     # cv2.drawMatchesKnn expects list of lists as matches.
# #     # opencv3.0有drawMatchesKnn函数
# #     # Apply ratio test
# #     # 比值测试，首先获取与A 距离最近的点B（最近）和C（次近），只有当B/C
# #     # 小于阈值时（0.75）才被认为是匹配，因为假设匹配是一一对应的，真正的匹配的理想距离为0
# #     good = []
# #     for m, n in matches:
# #         if m.distance < 0.7* n.distance:
# #             good.append([m])
# #     img3 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good[:], None, flags=2)
# #     #cv2.drawm
# #     plt.imshow(img3), plt.show()
# #
# #
# # matchSift3()
